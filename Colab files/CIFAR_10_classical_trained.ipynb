{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anubhavshrestha/sift_feature_extraction/blob/main/CIFAR_10_classical_trained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JrAtWFQ7wvP",
        "outputId": "4b3c1d05-fcc9-4fc0-f891-81cc1ae0d7f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 48813905.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               RandomCrop(size=(32, 32), padding=4)\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ToTensor()\n",
            "           )\n",
            "Files already downloaded and verified\n",
            "Training Accuracy for epoch 1 : 0.3766799867153168\n",
            "Training Accuracy for epoch 2 : 0.5324199795722961\n",
            "Training Accuracy for epoch 3 : 0.606440007686615\n",
            "Training Accuracy for epoch 4 : 0.6466599702835083\n",
            "Training Accuracy for epoch 5 : 0.6696599721908569\n",
            "Training Accuracy for epoch 6 : 0.6917799711227417\n",
            "Training Accuracy for epoch 7 : 0.7078999876976013\n",
            "Training Accuracy for epoch 8 : 0.7247399687767029\n",
            "Training Accuracy for epoch 9 : 0.7340999841690063\n",
            "Training Accuracy for epoch 10 : 0.7446199655532837\n",
            "Test accuracy: 74 %\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "transforms_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transforms_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transforms_train)\n",
        "\n",
        "print(trainset)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "                                          shuffle=True, num_workers = 0)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transforms_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "                                         shuffle=False, num_workers = 0)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__ (self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,64,4, stride=1, padding=2)\n",
        "        self.batch_normalize = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64,64,4, stride=1, padding=2)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.drop = nn.Dropout(p=0.5)\n",
        "        self.conv3 = nn.Conv2d(64,64,4, stride=1, padding=2)\n",
        "        self.conv4 = nn.Conv2d(64,64,4, stride=1, padding=2)\n",
        "        self.conv5 = nn.Conv2d(64,64,4, stride=1, padding=2)\n",
        "        self.conv6 = nn.Conv2d(64,64,3, stride=1, padding=0)\n",
        "        self.conv7 = nn.Conv2d(64,64,3, stride=1, padding=0)\n",
        "        self.conv8 = nn.Conv2d(64,64,3, stride=1, padding=0)\n",
        "        self.full_conn_1 = nn.Linear(64*4*4, 500)\n",
        "        self.full_conn_2 = nn.Linear(500, 500)\n",
        "        self.full_conn_3 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch_normalize(F.relu(self.conv1(x)))\n",
        "        x = self.drop(self.pool(F.relu(self.conv2(x))))\n",
        "        x = self.batch_normalize(F.relu(self.conv3(x)))\n",
        "        x = self.drop(self.pool(F.relu(self.conv4(x))))\n",
        "        x = self.batch_normalize(F.relu(self.conv5(x)))\n",
        "        x = self.drop(F.relu(self.conv6(x)))\n",
        "        x = self.batch_normalize(F.relu(self.conv7(x)))\n",
        "        x = self.drop(self.batch_normalize(F.relu(self.conv8(x))))\n",
        "        x = x.view(-1, 64*4*4)\n",
        "        x = F.relu(self.full_conn_1(x))\n",
        "        x = F.relu(self.full_conn_2(x))\n",
        "        x = self.full_conn_3(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "net.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# training the model\n",
        "\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    total_right = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        total_right += (predicted == labels.data).float().sum()\n",
        "\n",
        "    print(\"Training Accuracy for epoch {} : {}\".format(epoch+1,total_right/total))\n",
        "\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        torch.save(net, 'save_params.ckpt')\n",
        "\n",
        "# test the model\n",
        "\n",
        "my_model = torch.load('save_params.ckpt')\n",
        "\n",
        "total_right = 0\n",
        "total = 0\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
        "        outputs = my_model(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        total_right += (predicted == labels.data).float().sum()\n",
        "\n",
        "print('Test accuracy: %d %%' % (\n",
        "    100 * total_right / total))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RLWgUR7lqCeO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
