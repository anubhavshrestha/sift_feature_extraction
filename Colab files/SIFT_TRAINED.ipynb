{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPBHY36fsKxJTMLodHSmBqE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anubhavshrestha/sift_feature_extraction/blob/main/SIFT_TRAINED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Skiv7NTNn11q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6305bda7-70aa-4644-cfe1-a019cc61fdc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 100264575.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "\n",
        "transforms_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transforms_test = transforms.Compose([\n",
        "     transforms.ToTensor(),\n",
        "    # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform = transforms_train)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                          shuffle=True, num_workers = 0)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform = transforms_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                         shuffle=False, num_workers = 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def show_image(image, label):\n",
        "    plt.imshow(transforms.ToPILImage()(image))\n",
        "    plt.title(f\"Label: {label}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def show_sift_image(image):\n",
        "    image_np = np.array(transforms.ToPILImage()(image))  # Convert to NumPy array\n",
        "    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
        "    sift = cv2.SIFT_create()\n",
        "    kp = sift.detect(gray, None)\n",
        "\n",
        "    # Create a black image to draw SIFT keypoints on\n",
        "    sift_image = np.zeros_like(image_np)\n",
        "\n",
        "    # Draw SIFT keypoints on the black image\n",
        "    sift_image = cv2.drawKeypoints(image_np, kp, sift_image, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "    # print(sift_image)\n",
        "\n",
        "    # plt.imshow(sift_image.shape)\n",
        "    # print(\"HELLO!!!!\")\n",
        "    plt.title(\"SIFT Keypoints\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def extract_sift_features_and_visualize(image_tensor):\n",
        "    # Convert PyTorch tensor to NumPy array\n",
        "    image_tensor = image_tensor.permute(1,2,0)\n",
        "    image_np = image_tensor.numpy().astype(np.uint8)\n",
        "\n",
        "    # Convert NumPy array to BGR format (OpenCV image)\n",
        "    # img = cv2.cvtColor(np.transpose(image_np.astype(np.uint8), (1, 2, 0)), cv2.COLOR_RGB2BGR)\n",
        "    img = image_np\n",
        "\n",
        "    # Converting the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Initialize the SIFT detector\n",
        "    sift = cv2.SIFT_create()\n",
        "\n",
        "    # Detect keypoints in the image\n",
        "    kp = sift.detect(gray, None)\n",
        "\n",
        "    # Draw the keypoints on the image\n",
        "    # img_with_keypoints = cv2.drawKeypoints(img, kp, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "    img_with_keypoints=cv2.drawKeypoints(gray ,\n",
        "                      kp ,\n",
        "                      img ,\n",
        "                      flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "\n",
        "    # Visualize the original image and the image with SIFT keypoints side by side\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(cv2.cvtColor(img_with_keypoints, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Image with SIFT Keypoints')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # Save the image with keypoints\n",
        "    # cv2.imwrite('image-with-keypoints.jpg', img_with_keypoints)\n",
        "def convert_tensor_to_sift(image_tensor):\n",
        "# Convert the PyTorch tensor to a NumPy array and permute the dimensions\n",
        "  image_np = np.transpose(image_tensor.numpy(), (1, 2, 0))\n",
        "\n",
        "  # Convert to uint8 data type\n",
        "  image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "  # Convert to grayscale if the image has multiple channels\n",
        "  if image_np.shape[-1] == 3:\n",
        "      image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "  # Initialize the SIFT detector\n",
        "  sift = cv2.SIFT_create()\n",
        "\n",
        "  # Detect keypoints and compute descriptors\n",
        "  kp, des = sift.detectAndCompute(image_np, None)\n",
        "\n",
        "  keypoints_with_descriptors = np.hstack((np.array([kp[idx].pt for idx in range(len(kp))]), des))\n",
        "\n",
        "\n",
        "  # Draw the keypoints on the image\n",
        "  img_with_keypoints = cv2.drawKeypoints(image_np, kp, None)\n",
        "  # print(\"IMG WITH KEYPOINTS: \", img_with_keypoints)\n",
        "  shape = img_with_keypoints.shape\n",
        "  # print(\"THE SHAPE IS: \", shape)\n",
        "\n",
        "  # Visualize the image with keypoints\n",
        "  # plt.imshow(img_with_keypoints)\n",
        "  # plt.title('Image with SIFT Keypoints')\n",
        "  # plt.axis('off')\n",
        "  # plt.show()\n",
        "  # print(\"KP: \",len(kp))\n",
        "  # print(\"DESCRIPTOR: \",des.shape)\n",
        "  # print(des)\n",
        "  return torch.tensor(np.transpose(img_with_keypoints,(2,0,1)))\n",
        "\n",
        "def convert_images_to_sift(image_tensors):\n",
        "  sift_tensors = []\n",
        "  for image_tensor in image_tensors:\n",
        "    sift_tensor = convert_tensor_to_sift(image_tensor)\n",
        "    sift_tensors.append(sift_tensor)\n",
        "\n",
        "  stacked_sift_tensors = torch.stack(sift_tensors)\n",
        "  return stacked_sift_tensors\n"
      ],
      "metadata": {
        "id": "sf630Gznlb4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in trainloader:\n",
        "  images, labels = data\n",
        "  print(\"IMAGeS SHAPE: \", images.shape)\n",
        "  for image, label in zip(images,labels):\n",
        "    print(type(image))\n",
        "    show_image(image, label)\n",
        "    print(convert_tensor_to_sift(image).shape)\n",
        "    break\n",
        "  x = convert_images_to_sift(images)\n",
        "  print(\"CONVERTED SHAPE = \", x.shape)\n",
        "  show_image(x[0], 1)\n",
        "  print(type(x))\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "id": "zkbbm1Wbl4fS",
        "outputId": "65a271b7-59c8-4f59-d3c3-db51b01421ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMAGeS SHAPE:  torch.Size([128, 3, 32, 32])\n",
            "<class 'torch.Tensor'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n",
            "CONVERTED SHAPE =  torch.Size([128, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__ (self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,64,4, stride=1, padding=2)\n",
        "        self.batch_normalize = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64,64,4, stride=1, padding=2)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.drop = nn.Dropout(p=0.5)\n",
        "        self.conv3 = nn.Conv2d(64,64,4, stride=1, padding=2)\n",
        "        self.conv4 = nn.Conv2d(64,64,4, stride=1, padding=2)\n",
        "        self.conv5 = nn.Conv2d(64,64,4, stride=1, padding=2)\n",
        "        self.conv6 = nn.Conv2d(64,64,3, stride=1, padding=0)\n",
        "        self.conv7 = nn.Conv2d(64,64,3, stride=1, padding=0)\n",
        "        self.conv8 = nn.Conv2d(64,64,3, stride=1, padding=0)\n",
        "        self.full_conn_1 = nn.Linear(64*4*4, 500)\n",
        "        self.full_conn_2 = nn.Linear(500, 500)\n",
        "        self.full_conn_3 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch_normalize(F.relu(self.conv1(x)))\n",
        "        x = self.drop(self.pool(F.relu(self.conv2(x))))\n",
        "        x = self.batch_normalize(F.relu(self.conv3(x)))\n",
        "        x = self.drop(self.pool(F.relu(self.conv4(x))))\n",
        "        x = self.batch_normalize(F.relu(self.conv5(x)))\n",
        "        x = self.drop(F.relu(self.conv6(x)))\n",
        "        x = self.batch_normalize(F.relu(self.conv7(x)))\n",
        "        x = self.drop(self.batch_normalize(F.relu(self.conv8(x))))\n",
        "        x = x.view(-1, 64*4*4)\n",
        "        x = F.relu(self.full_conn_1(x))\n",
        "        x = F.relu(self.full_conn_2(x))\n",
        "        x = self.full_conn_3(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "net.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# training the model\n",
        "\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    total_right = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = convert_images_to_sift(inputs)\n",
        "        inputs = inputs.to(torch.float32)\n",
        "        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        total_right += (predicted == labels.data).float().sum()\n",
        "\n",
        "    print(\"Training Accuracy for epoch {} : {}\".format(epoch+1,total_right/total))\n",
        "\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        torch.save(net, 'save_params.ckpt')\n",
        "\n",
        "# test the model\n",
        "\n",
        "my_model = torch.load('save_params.ckpt')\n",
        "\n",
        "total_right = 0\n",
        "total = 0\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = convert_images_to_sift(images)\n",
        "        images = images.to(torch.float32)\n",
        "        images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
        "        outputs = my_model(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        total_right += (predicted == labels.data).float().sum()\n",
        "\n",
        "print('Test accuracy: %d %%' % (\n",
        "    100 * total_right / total))"
      ],
      "metadata": {
        "id": "HtzBoj8cl6VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    total_right = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = convert_images_to_sift(inputs)\n",
        "        inputs = inputs.to(torch.float32)\n",
        "        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        total_right += (predicted == labels.data).float().sum()\n",
        "\n",
        "    print(\"Training Accuracy for epoch {} : {}\".format(epoch+1,total_right/total))\n",
        "\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        torch.save(net, 'save_params.ckpt')\n",
        "\n",
        "# test the model\n",
        "\n",
        "my_model = torch.load('save_params.ckpt')\n",
        "\n",
        "total_right = 0\n",
        "total = 0\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = convert_images_to_sift(images)\n",
        "        images = images.to(torch.float32)\n",
        "        images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
        "        outputs = my_model(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        total_right += (predicted == labels.data).float().sum()\n",
        "\n",
        "print('Test accuracy: %d %%' % (\n",
        "    100 * total_right / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thabsa1ofIlB",
        "outputId": "1756388c-b82a-4654-da0f-581aa6c53f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for epoch 1 : 0.5791599750518799\n",
            "Training Accuracy for epoch 2 : 0.585379958152771\n",
            "Training Accuracy for epoch 3 : 0.5965399742126465\n",
            "Training Accuracy for epoch 4 : 0.5969399809837341\n",
            "Training Accuracy for epoch 5 : 0.6065999865531921\n",
            "Training Accuracy for epoch 6 : 0.6099199652671814\n",
            "Training Accuracy for epoch 7 : 0.615619957447052\n",
            "Training Accuracy for epoch 8 : 0.6229400038719177\n",
            "Training Accuracy for epoch 9 : 0.6263200044631958\n",
            "Training Accuracy for epoch 10 : 0.6256399750709534\n",
            "Test accuracy: 62 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E-2xrCCVjchl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
