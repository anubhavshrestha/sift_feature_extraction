{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMoqfuI0nDbwDqBieDhVpbS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anubhavshrestha/sift_feature_extraction/blob/main/SIFT_TRAINED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Skiv7NTNn11q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a76cf8-5640-4424-b9f3-b8b4e967123d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 43129819.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "\n",
        "transforms_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transforms_test = transforms.Compose([\n",
        "     transforms.ToTensor(),\n",
        "    # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform = transforms_train)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                          shuffle=True, num_workers = 0)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform = transforms_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                         shuffle=False, num_workers = 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def show_image(image, label):\n",
        "    plt.imshow(transforms.ToPILImage()(image))\n",
        "    plt.title(f\"Label: {label}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def show_sift_image(image):\n",
        "    image_np = np.array(transforms.ToPILImage()(image))  # Convert to NumPy array\n",
        "    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
        "    sift = cv2.SIFT_create()\n",
        "    kp = sift.detect(gray, None)\n",
        "\n",
        "    # Create a black image to draw SIFT keypoints on\n",
        "    sift_image = np.zeros_like(image_np)\n",
        "\n",
        "    # Draw SIFT keypoints on the black image\n",
        "    sift_image = cv2.drawKeypoints(image_np, kp, sift_image, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "    # print(sift_image)\n",
        "\n",
        "    # plt.imshow(sift_image.shape)\n",
        "    # print(\"HELLO!!!!\")\n",
        "    plt.title(\"SIFT Keypoints\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def extract_sift_features_and_visualize(image_tensor):\n",
        "    # Convert PyTorch tensor to NumPy array\n",
        "    image_tensor = image_tensor.permute(1,2,0)\n",
        "    image_np = image_tensor.numpy().astype(np.uint8)\n",
        "\n",
        "    # Convert NumPy array to BGR format (OpenCV image)\n",
        "    # img = cv2.cvtColor(np.transpose(image_np.astype(np.uint8), (1, 2, 0)), cv2.COLOR_RGB2BGR)\n",
        "    img = image_np\n",
        "\n",
        "    # Converting the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Initialize the SIFT detector\n",
        "    sift = cv2.SIFT_create()\n",
        "\n",
        "    # Detect keypoints in the image\n",
        "    kp = sift.detect(gray, None)\n",
        "\n",
        "    # Draw the keypoints on the image\n",
        "    # img_with_keypoints = cv2.drawKeypoints(img, kp, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "    img_with_keypoints=cv2.drawKeypoints(gray ,\n",
        "                      kp ,\n",
        "                      img ,\n",
        "                      flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "\n",
        "    # Visualize the original image and the image with SIFT keypoints side by side\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(cv2.cvtColor(img_with_keypoints, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Image with SIFT Keypoints')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # Save the image with keypoints\n",
        "    # cv2.imwrite('image-with-keypoints.jpg', img_with_keypoints)\n",
        "def convert_tensor_to_sift(image_tensor):\n",
        "# Convert the PyTorch tensor to a NumPy array and permute the dimensions\n",
        "  image_np = np.transpose(image_tensor.numpy(), (1, 2, 0))\n",
        "\n",
        "  # Convert to uint8 data type\n",
        "  image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "  # Convert to grayscale if the image has multiple channels\n",
        "  if image_np.shape[-1] == 3:\n",
        "      image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "  # Initialize the SIFT detector\n",
        "  sift = cv2.SIFT_create()\n",
        "\n",
        "  # Detect keypoints and compute descriptors\n",
        "  kp, des = sift.detectAndCompute(image_np, None)\n",
        "\n",
        "  keypoints_with_descriptors = np.hstack((np.array([kp[idx].pt for idx in range(len(kp))]), des))\n",
        "\n",
        "\n",
        "  # Draw the keypoints on the image\n",
        "  img_with_keypoints = cv2.drawKeypoints(image_np, kp, None)\n",
        "  # print(\"IMG WITH KEYPOINTS: \", img_with_keypoints)\n",
        "  shape = img_with_keypoints.shape\n",
        "  # print(\"THE SHAPE IS: \", shape)\n",
        "\n",
        "  # Visualize the image with keypoints\n",
        "  # plt.imshow(img_with_keypoints)\n",
        "  # plt.title('Image with SIFT Keypoints')\n",
        "  # plt.axis('off')\n",
        "  # plt.show()\n",
        "  # print(\"KP: \",len(kp))\n",
        "  # print(\"DESCRIPTOR: \",des.shape)\n",
        "  # print(des)\n",
        "  return torch.tensor(np.transpose(img_with_keypoints,(2,0,1)))\n",
        "\n",
        "def convert_images_to_sift(image_tensors):\n",
        "  sift_tensors = []\n",
        "  for image_tensor in image_tensors:\n",
        "    sift_tensor = convert_tensor_to_sift(image_tensor)\n",
        "    sift_tensors.append(sift_tensor)\n",
        "\n",
        "  stacked_sift_tensors = torch.stack(sift_tensors)\n",
        "  return stacked_sift_tensors\n"
      ],
      "metadata": {
        "id": "sf630Gznlb4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in trainloader:\n",
        "  images, labels = data\n",
        "  print(\"IMAGeS SHAPE: \", images.shape)\n",
        "  for image, label in zip(images,labels):\n",
        "    print(type(image))\n",
        "    show_image(image, label)\n",
        "    print(convert_tensor_to_sift(image).shape)\n",
        "    break\n",
        "  x = convert_images_to_sift(images)\n",
        "  print(\"CONVERTED SHAPE = \", x.shape)\n",
        "  show_image(x[0], 1)\n",
        "  print(type(x))\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "id": "zkbbm1Wbl4fS",
        "outputId": "e65eb613-62f6-49cb-a3ee-f06b9fb9b98a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMAGeS SHAPE:  torch.Size([128, 3, 32, 32])\n",
            "<class 'torch.Tensor'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n",
            "CONVERTED SHAPE =  torch.Size([128, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__ (self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,64,4, stride=1, padding=2)\n",
        "        self.batch_normalize = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64,64,4, stride=1, padding=2)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.drop = nn.Dropout(p=0.5)\n",
        "        self.conv3 = nn.Conv2d(64,64,4, stride=1, padding=2)\n",
        "        self.conv4 = nn.Conv2d(64,64,4, stride=1, padding=2)\n",
        "        self.conv5 = nn.Conv2d(64,64,4, stride=1, padding=2)\n",
        "        self.conv6 = nn.Conv2d(64,64,3, stride=1, padding=0)\n",
        "        self.conv7 = nn.Conv2d(64,64,3, stride=1, padding=0)\n",
        "        self.conv8 = nn.Conv2d(64,64,3, stride=1, padding=0)\n",
        "        self.full_conn_1 = nn.Linear(64*4*4, 500)\n",
        "        self.full_conn_2 = nn.Linear(500, 500)\n",
        "        self.full_conn_3 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch_normalize(F.relu(self.conv1(x)))\n",
        "        x = self.drop(self.pool(F.relu(self.conv2(x))))\n",
        "        x = self.batch_normalize(F.relu(self.conv3(x)))\n",
        "        x = self.drop(self.pool(F.relu(self.conv4(x))))\n",
        "        x = self.batch_normalize(F.relu(self.conv5(x)))\n",
        "        x = self.drop(F.relu(self.conv6(x)))\n",
        "        x = self.batch_normalize(F.relu(self.conv7(x)))\n",
        "        x = self.drop(self.batch_normalize(F.relu(self.conv8(x))))\n",
        "        x = x.view(-1, 64*4*4)\n",
        "        x = F.relu(self.full_conn_1(x))\n",
        "        x = F.relu(self.full_conn_2(x))\n",
        "        x = self.full_conn_3(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "net.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# training the model\n",
        "\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    total_right = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = convert_images_to_sift(inputs)\n",
        "        inputs = inputs.to(torch.float32)\n",
        "        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        total_right += (predicted == labels.data).float().sum()\n",
        "\n",
        "    print(\"Training Accuracy for epoch {} : {}\".format(epoch+1,total_right/total))\n",
        "\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        torch.save(net, 'save_params.ckpt')\n",
        "\n",
        "# test the model\n",
        "\n",
        "my_model = torch.load('save_params.ckpt')\n",
        "\n"
      ],
      "metadata": {
        "id": "HtzBoj8cl6VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    total_right = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = convert_images_to_sift(inputs)\n",
        "        inputs = inputs.to(torch.float32)\n",
        "        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        total_right += (predicted == labels.data).float().sum()\n",
        "\n",
        "    print(\"Training Accuracy for epoch {} : {}\".format(epoch+1,total_right/total))\n",
        "\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        torch.save(net, 'save_params.ckpt')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thabsa1ofIlB",
        "outputId": "b7fcd472-7ac9-4b16-e99f-37a8176d0da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for epoch 1 : 0.6756599545478821\n",
            "Training Accuracy for epoch 2 : 0.6773599982261658\n",
            "Training Accuracy for epoch 3 : 0.6784600019454956\n",
            "Training Accuracy for epoch 4 : 0.676539957523346\n",
            "Training Accuracy for epoch 5 : 0.6803999543190002\n",
            "Training Accuracy for epoch 6 : 0.6818000078201294\n",
            "Training Accuracy for epoch 7 : 0.6845799684524536\n",
            "Training Accuracy for epoch 8 : 0.6819999814033508\n",
            "Training Accuracy for epoch 9 : 0.6834999918937683\n",
            "Training Accuracy for epoch 10 : 0.6875999569892883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = torch.load('save_params.ckpt')\n",
        "\n",
        "total_right = 0\n",
        "total = 0\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = convert_images_to_sift(images)\n",
        "        images = images.to(torch.float32)\n",
        "        images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
        "        outputs = my_model(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        total_right += (predicted == labels.data).float().sum()\n",
        "\n",
        "print('Test accuracy: %d %%' % (\n",
        "    100 * total_right / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fu0272WzAH",
        "outputId": "338dad25-d832-4a89-e8b8-67a8b0f12c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 66 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N0b3nur9vj3p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
