{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMHuPQazTw96w7Uon0pYkDl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anubhavshrestha/sift_feature_extraction/blob/main/CIFAR_10_FIN_PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ42MGRjxeOI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define PCA-based feature extraction\n",
        "def extract_sift_and_reduce_dimensionality(image, pca):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    sift = cv2.SIFT_create()\n",
        "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
        "    if descriptors is not None:\n",
        "        reduced_descriptors = pca.transform(descriptors)\n",
        "        return reduced_descriptors\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Perform PCA dimensionality reduction\n",
        "def reduce_dimensionality(descriptors, n_components=64):\n",
        "    pca = PCA(n_components=n_components)\n",
        "    reduced_descriptors = pca.fit_transform(descriptors)\n",
        "    return pca, reduced_descriptors\n",
        "\n",
        "# Initialize PCA and perform dimensionality reduction (you may adjust n_components)\n",
        "pca, _ = reduce_dimensionality(train_sift_features, n_components=64)"
      ],
      "metadata": {
        "id": "h_C3tU8jx4jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to extract SIFT features from an image\n",
        "def extract_sift_features(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    sift = cv2.SIFT_create()\n",
        "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
        "    return descriptors\n",
        "\n",
        "# Define a custom dataset that computes SIFT features for each image\n",
        "class SIFTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.dataset[idx]\n",
        "        sift_features = extract_sift_features(img)  # Extract SIFT features\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return sift_features, label\n",
        "\n",
        "# Create data transforms (you can modify these as needed)\n",
        "transforms_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transforms_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=None)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=None)\n",
        "\n",
        "# Create custom SIFT datasets\n",
        "sift_trainset = SIFTDataset(trainset, transform=transforms_train)\n",
        "sift_testset = SIFTDataset(testset, transform=transforms_test)\n",
        "\n",
        "# Define your neural network model (modify as needed)\n",
        "class SimpleFNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleFNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(128, 64)  # Input size 128 (SIFT feature dimension), output size 64\n",
        "        self.fc2 = nn.Linear(64, 10)   # Output size 10 (number of classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model and optimizer\n",
        "model = SimpleFNN()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Set device to GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# DataLoader for SIFT datasets\n",
        "batch_size = 128\n",
        "sift_trainloader = torch.utils.data.DataLoader(sift_trainset, batch_size=batch_size, shuffle=True)\n",
        "sift_testloader = torch.utils.data.DataLoader(sift_testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for sift_features, labels in sift_trainloader:\n",
        "        sift_features, labels = sift_features.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(sift_features.float())\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(sift_trainloader):.4f}, \"\n",
        "          f\"Accuracy: {100 * total_correct / total_samples:.2f}%\")\n",
        "\n",
        "print(\"Training finished!\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for sift_features, labels in sift_testloader:\n",
        "        sift_features, labels = sift_features.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(sift_features.float())\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "XzOvtxBvynff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SDcxn3abzke4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
